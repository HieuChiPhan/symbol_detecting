{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_EMNIST (2).ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "LEmI-6hYwgJx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3zpkSxkoe6af",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KJ3A0lFgSUuc",
        "colab_type": "code",
        "outputId": "ee8beec6-6541-44a8-cd5e-551ea7699945",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "cell_type": "code",
      "source": [
        "link = 'https://drive.google.com/open?id=1lLa0K2SmZubQ65uoWJdSwv5mQV1QSetd'\n",
        "file_name='data'\n",
        "fluff, id = link.split('=')\n",
        "# print (id)\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile(file_name)  \n",
        "# from sklearn.externals import joblib\n",
        "dataset=pd.read_csv(file_name, header=None)\n",
        "dataset.head(5)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0    1    2    3    4    5    6    7    8    9   ...   775  776  777  778  \\\n",
              "0   45    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
              "1   36    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
              "2   43    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
              "3   15    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
              "4    4    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
              "\n",
              "   779  780  781  782  783  784  \n",
              "0    0    0    0    0    0    0  \n",
              "1    0    0    0    0    0    0  \n",
              "2    0    0    0    0    0    0  \n",
              "3    0    0    0    0    0    0  \n",
              "4    0    0    0    0    0    0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "oy1YKXo-TPAi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# max(dataset.iloc[2, 1:])\n",
        "# Y[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9NGUK1L-4CgE",
        "colab_type": "code",
        "outputId": "d7c16c55-1c6b-4fd0-f20b-506452c06d72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2330
        }
      },
      "cell_type": "code",
      "source": [
        "X = dataset.iloc[:, 1:].values\n",
        "X=X.reshape((112800, 28*28))\n",
        "y = dataset.iloc[:, 0].values\n",
        "\n",
        "# Encoding categorical data\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "#labelencoder_X_1 = LabelEncoder()\n",
        "#X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
        "#labelencoder_X_2 = LabelEncoder()\n",
        "#X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
        "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
        "Y = onehotencoder.fit_transform(y.reshape(-1, 1)).toarray()\n",
        "#X = X[:, 1:]\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
        "X_train=X\n",
        "y_train=Y.astype(\"int\")\n",
        "\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "#XX_test = sc.transform(XX_test)\n",
        "\n",
        "X_train = X_train.reshape(-1, 28, 28, 1).astype(\"float32\")\n",
        "#XX_test = XX_test.reshape(-1, 28, 28, 1).astype(\"float32\")\n",
        "\n",
        "\n",
        "# Part 1 - Building the CNN\n",
        "\n",
        "# Importing the Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense,BatchNormalization,Dropout\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "classifier = Sequential()\n",
        " \n",
        "classifier.add(Convolution2D(filters = 64, kernel_size = (5, 5), activation='relu', input_shape = (28, 28, 1)))\n",
        "classifier.add(BatchNormalization())\n",
        "classifier.add(Convolution2D(filters = 128, kernel_size = (5, 5), activation='relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "classifier.add(MaxPooling2D(strides=(2,2)))\n",
        "classifier.add(Dropout(0.25))\n",
        "classifier.add(Convolution2D(filters = 256, kernel_size = (5, 5), activation='relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "classifier.add(Convolution2D(filters = 512, kernel_size = (5, 5), activation='relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "classifier.add(MaxPooling2D(strides=(2,2)))\n",
        "classifier.add(Dropout(0.25))\n",
        "\n",
        "classifier.add(Flatten())\n",
        "#classifier.add(Dense(1024, activation='relu'))\n",
        "#classifier.add(Dropout(0.25))\n",
        "classifier.add(Dense(512, activation='relu'))\n",
        "classifier.add(Dropout(0.25))\n",
        "classifier.add(Dense(256, activation='relu'))\n",
        "classifier.add(Dropout(0.5))\n",
        "classifier.add(Dense(47, activation='softmax'))\n",
        "\n",
        "\n",
        "classifier.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=[\"accuracy\"])\n",
        "\n",
        "# Part 2 - Fitting the CNN to the images\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range = 0.2,\n",
        "                            height_shift_range = 0.2,\n",
        "                            width_shift_range = 0.2,\n",
        "                            rotation_range = 10,\n",
        "                            shear_range=0.2)\n",
        "#                             horizontal_flip = True # Many symbol will be confused with horizontal flip such as W and M\n",
        "\n",
        "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\n",
        "\n",
        "hist = classifier.fit_generator(datagen.flow(X_train, y_train, batch_size=16),\n",
        "                           steps_per_epoch=1000,\n",
        "                           epochs=60, #Increase this when not on Kaggle kernel\n",
        "                           verbose=1,  #1 for ETA, 0 for silent\n",
        "#                           validation_data=(X_test[:400,:], y_val[:400,:]))#, #For speed\n",
        "                           callbacks=[annealer])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
            "  warnings.warn(msg, DataConversionWarning)\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 3.5177 - acc: 0.1043\n",
            "Epoch 2/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 2.3693 - acc: 0.3132\n",
            "Epoch 3/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 1.7524 - acc: 0.4731\n",
            "Epoch 4/60\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 1.4519 - acc: 0.5649\n",
            "Epoch 5/60\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 1.2597 - acc: 0.6133\n",
            "Epoch 6/60\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 1.1647 - acc: 0.6467\n",
            "Epoch 7/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 1.0800 - acc: 0.6695\n",
            "Epoch 8/60\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.9705 - acc: 0.6972\n",
            "Epoch 9/60\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.9328 - acc: 0.7077\n",
            "Epoch 10/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.8870 - acc: 0.7209\n",
            "Epoch 11/60\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.8606 - acc: 0.7336\n",
            "Epoch 12/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.8291 - acc: 0.7475\n",
            "Epoch 13/60\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.8132 - acc: 0.7512\n",
            "Epoch 14/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.7712 - acc: 0.7590\n",
            "Epoch 15/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.7240 - acc: 0.7679\n",
            "Epoch 16/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.7219 - acc: 0.7703\n",
            "Epoch 17/60\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.7022 - acc: 0.7758\n",
            "Epoch 18/60\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.6985 - acc: 0.7769\n",
            "Epoch 19/60\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.6764 - acc: 0.7864\n",
            "Epoch 20/60\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.6658 - acc: 0.7891\n",
            "Epoch 21/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6694 - acc: 0.7905\n",
            "Epoch 22/60\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.6460 - acc: 0.7969\n",
            "Epoch 23/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6388 - acc: 0.7976\n",
            "Epoch 24/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.6224 - acc: 0.8011\n",
            "Epoch 25/60\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.6109 - acc: 0.8034\n",
            "Epoch 26/60\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.6141 - acc: 0.8023\n",
            "Epoch 27/60\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.6149 - acc: 0.8057\n",
            "Epoch 28/60\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.6094 - acc: 0.8066\n",
            "Epoch 29/60\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.5879 - acc: 0.8051\n",
            "Epoch 30/60\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.5929 - acc: 0.8091\n",
            "Epoch 31/60\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.5939 - acc: 0.8072\n",
            "Epoch 32/60\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.5804 - acc: 0.8101\n",
            "Epoch 33/60\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.5696 - acc: 0.8132\n",
            "Epoch 34/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5702 - acc: 0.8113\n",
            "Epoch 35/60\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.5850 - acc: 0.8151\n",
            "Epoch 36/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5741 - acc: 0.8151\n",
            "Epoch 37/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5792 - acc: 0.8149\n",
            "Epoch 38/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5645 - acc: 0.8151\n",
            "Epoch 39/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5443 - acc: 0.8211\n",
            "Epoch 40/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5745 - acc: 0.8113\n",
            "Epoch 41/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5822 - acc: 0.8170\n",
            "Epoch 42/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5648 - acc: 0.8142\n",
            "Epoch 43/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5546 - acc: 0.8185\n",
            "Epoch 44/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5561 - acc: 0.8199\n",
            "Epoch 45/60\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.5552 - acc: 0.8187\n",
            "Epoch 46/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5448 - acc: 0.8219\n",
            "Epoch 47/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5560 - acc: 0.8200\n",
            "Epoch 48/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5659 - acc: 0.8161\n",
            "Epoch 49/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5658 - acc: 0.8179\n",
            "Epoch 50/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5560 - acc: 0.8175\n",
            "Epoch 51/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5533 - acc: 0.8178\n",
            "Epoch 52/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5614 - acc: 0.8166\n",
            "Epoch 53/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5507 - acc: 0.8223\n",
            "Epoch 54/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5749 - acc: 0.8148\n",
            "Epoch 55/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5670 - acc: 0.8179\n",
            "Epoch 56/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5434 - acc: 0.8228\n",
            "Epoch 57/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5619 - acc: 0.8222\n",
            "Epoch 58/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5646 - acc: 0.8171\n",
            "Epoch 59/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5526 - acc: 0.8203\n",
            "Epoch 60/60\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5528 - acc: 0.8240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vROvYjrb4bfV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "a2bdecd5-083e-487f-898c-da290d6b60ab"
      },
      "cell_type": "code",
      "source": [
        "classifier.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 64)        1664      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 20, 20, 128)       204928    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 20, 20, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 10, 10, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 6, 6, 256)         819456    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 6, 6, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 2, 2, 512)         3277312   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 47)                12079     \n",
            "=================================================================\n",
            "Total params: 4,713,263\n",
            "Trainable params: 4,711,343\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vQ41RbKz6VRO",
        "colab_type": "code",
        "outputId": "28d11e2d-5454-42f8-b796-e1d6ce818c95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# # save the model to disk\n",
        "from sklearn.externals import joblib\n",
        "filename = 'EMNIST_model.h5'\n",
        "joblib.dump(classifier, filename)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['EMNIST_model.h5']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "vHYl31n38l0A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "files.download(filename)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}